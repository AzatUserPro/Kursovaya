import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from sklearn.ensemble import RandomForestRegressor

# === 1. –ó–ê–ì–†–£–ó–ö–ê –ò –û–ß–ò–°–¢–ö–ê –î–ê–ù–ù–´–• ===
@st.cache_data
def load_and_clean():
    df = pd.read_csv('data.csv', sep=';', on_bad_lines='skip', header=None)

    columns = [
        "federal_district", "federal_district_short", "region_code", "region_name",
        "okato", "id", "name", "name_short", "year",
        "e1", "e2", "e3", "e4", "e5", "e6", "e8",
        "ege_budg", "wos", "scopus", "rsci", "rnd",
        "total_income", "square", "phd_share", "pps",
        "rnd_private", "pk"
    ]

    if df.shape[1] > len(columns):
        df = df.iloc[:, :len(columns)]
    elif df.shape[1] < len(columns):
        for _ in range(len(columns) - df.shape[1]):
            df[len(df.columns)] = np.nan

    df.columns = columns

    df.dropna(how='all', inplace=True)
    df.drop_duplicates(inplace=True)
    df.dropna(subset=['year', 'e1', 'name_short'], inplace=True)

    numeric_cols = [c for c in columns if c not in ["federal_district", "federal_district_short",
                                                    "region_name", "name", "name_short", "okato"]]
    df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')

    # e1 –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ 0‚Äì100
    df = df[(df['e1'] >= 0) & (df['e1'] <= 100)]
    df.dropna(subset=['e1'], inplace=True)
    df.reset_index(drop=True, inplace=True)
    return df

df_raw = load_and_clean()

# === 2. –§–ò–õ–¨–¢–†–´ (–±–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å) ===
st.sidebar.title("üéõÔ∏è –§–∏–ª—å—Ç—Ä—ã")
selected_fd = st.sidebar.multiselect(
    "–§–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –æ–∫—Ä—É–≥",
    options=sorted(df_raw['federal_district'].unique())
)
selected_year = st.sidebar.slider(
    "–ì–æ–¥",
    min_value=2013,
    max_value=2017,
    value=(2013, 2017)
)

# –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
filtered_df = df_raw.copy()
if selected_fd:
    filtered_df = filtered_df[filtered_df['federal_district'].isin(selected_fd)]
filtered_df = filtered_df[
    (filtered_df['year'] >= selected_year[0]) &
    (filtered_df['year'] <= selected_year[1])
]

# === 3. –ß–ò–¢–ê–ï–ú–´–ï –ù–ê–ó–í–ê–ù–ò–Ø –ú–ï–¢–†–ò–ö ===
metric_labels = {
    'e1': '–ë–∞–ª–ª –ï–ì–≠ —Å —É—á—ë—Ç–æ–º –ª—å–≥–æ—Ç–Ω–∏–∫–æ–≤ = 100',
    'e2': '–°—Ä–µ–¥—Å—Ç–≤–∞ –æ—Ç –ù–ò–û–ö–† –Ω–∞ –Ω–∞—É—á–Ω–æ-–ø–µ–¥–∞–≥–æ–≥–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞–±–æ—Ç–Ω–∏–∫–∞ (—Ç—ã—Å. —Ä—É–±.)',
    'e3': '–î–æ–ª—è –∏–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã—Ö —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ (%)',
    'e4': '–°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª –ï–ì–≠ –ø–æ—Å—Ç—É–ø–∏–≤—à–∏—Ö –Ω–∞ –±—é–¥–∂–µ—Ç (–≤—Å–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è)',
    'e5': '–ó–∞—Ä–ø–ª–∞—Ç–∞ –ü–ü–° –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Å—Ä–µ–¥–Ω–µ–π –ø–æ —Ä–µ–≥–∏–æ–Ω—É (%)',
    'e6': '–¢—Ä—É–¥–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –≤—ã–ø—É—Å–∫–Ω–∏–∫–æ–≤ (%)',
    'e8': '–ß–∏—Å–ª–æ –ü–ü–° —Å —É—á—ë–Ω–æ–π —Å—Ç–µ–ø–µ–Ω—å—é –Ω–∞ 100 —Å—Ç—É–¥–µ–Ω—Ç–æ–≤',
    'ege_budg': '–°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª –ï–ì–≠ –Ω–∞ –±—é–¥–∂–µ—Ç–µ (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Ä–∞—Å—á—ë—Ç)',
    'phd_share': '–î–æ–ª—è –∞—Å–ø–∏—Ä–∞–Ω—Ç–æ–≤ (%)',
    'rnd': '–û–±—â–∏–π –æ–±—ä—ë–º –ù–ò–û–ö–† (—Ç—ã—Å. —Ä—É–±.)',
    'wos': '–ü—É–±–ª–∏–∫–∞—Ü–∏–∏ –≤ Web of Science –Ω–∞ 100 –ù–ü–†',
    'scopus': '–ü—É–±–ª–∏–∫–∞—Ü–∏–∏ –≤ Scopus –Ω–∞ 100 –ù–ü–†',
    'rsci': '–ü—É–±–ª–∏–∫–∞—Ü–∏–∏ –≤ –†–ò–ù–¶ –Ω–∞ 100 –ù–ü–†',
    'total_income': '–î–æ—Ö–æ–¥—ã –≤—É–∑–∞ –∏–∑ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ (—Ç—ã—Å. —Ä—É–±.)',
    'square': '–û–±—â–∞—è –ø–ª–æ—â–∞–¥—å –∑–¥–∞–Ω–∏–π (–∫–≤. –º)',
    'pps': '–ß–∏—Å–ª–æ –ü–ü–°',
    'rnd_private': '–û–±—ä—ë–º –ù–ò–û–ö–† –ø–æ –∑–∞–∫–∞–∑–∞–º —é—Ä–ª–∏—Ü (—Ç—ã—Å. —Ä—É–±.)',
    'pk': '–ß–∏—Å–ª–æ –ü–ö –Ω–∞ —Å—Ç—É–¥–µ–Ω—Ç–∞'
}

# === 4. –í–´–ë–û–† –ó–ê–î–ê–ß–ò ===
st.sidebar.title("üìã –í—ã–±–µ—Ä–∏—Ç–µ –∑–∞–¥–∞—á—É")
task = st.sidebar.radio("–¶–µ–ª—å –∞–Ω–∞–ª–∏–∑–∞:", [
    "1. –û–±–∑–æ—Ä –≤—Å–µ—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π: –æ–ø–∏—Å–∞—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –≥—Ä–∞—Ñ–∏–∫–∏",
    "2. –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–∏—ë–º–∞ –∞–±–∏—Ç—É—Ä–∏–µ–Ω—Ç–æ–≤",
    "3. –ü—Ä–æ–≥–Ω–æ–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–∏—ë–º–∞ –Ω–∞ 2018 –≥–æ–¥",
    "4. –§–∞–∫—Ç–æ—Ä—ã, –≤–ª–∏—è—é—â–∏–µ –Ω–∞ –±–∞–ª–ª—ã –∞–±–∏—Ç—É—Ä–µ–Ω—Ç–æ–≤",
    "5. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—É–∑–æ–≤ –ø–æ –∫–ª—é—á–µ–≤—ã–º –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è–º",
    "6. –ü–æ–¥–±–æ—Ä –≤—É–∑–∞ –ø–æ –≤–∞—à–∏–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º",
    "7. –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –≤—É–∑–æ–≤",
    "8. –ü–æ–¥–±–æ—Ä –≤—É–∑–∞ –ø–æ –≤–∞—à–∏–º –±–∞–ª–ª–∞–º –ï–ì–≠"])

# === –ó–ê–î–ê–ß–ê 1: –û–¶–ï–ù–ö–ê –ö–ê–ß–ï–°–¢–í–ê –î–ê–ù–ù–´–• ===
if task == "1. –û–±–∑–æ—Ä –≤—Å–µ—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π: –æ–ø–∏—Å–∞—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –≥—Ä–∞—Ñ–∏–∫–∏":
    st.title("üîç –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö")

    # --- 1. –û–±—â–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ ---
    st.subheader("1. –û–±—â–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞")
    st.write(f"- **–ó–∞–ø–∏—Å–µ–π (—Å—Ç—Ä–æ–∫)**: {len(df_raw):,}")
    st.write(f"- **–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≤—É–∑–æ–≤**: {df_raw['name_short'].nunique():,}")
    st.write(f"- **–ì–æ–¥—ã –Ω–∞–±–ª—é–¥–µ–Ω–∏–π**: {df_raw['year'].min()} ‚Äì {df_raw['year'].max()}")
    st.write(f"- **–§–µ–¥–µ—Ä–∞–ª—å–Ω—ã—Ö –æ–∫—Ä—É–≥–æ–≤**: {df_raw['federal_district'].nunique()}")

    # --- 2. –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è ---
    st.subheader("2. –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (NaN)")
    missing = df_raw.isna().sum()
    missing_pct = (missing / len(df_raw)) * 100
    missing_df = pd.DataFrame({
        '–ü—Ä–æ–ø—É—Å–∫–æ–≤': missing,
        '% –ø—Ä–æ–ø—É—Å–∫–æ–≤': missing_pct.round(2)
    })
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç–æ–ª–±—Ü—ã —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏
    missing_df = missing_df[missing_df['–ü—Ä–æ–ø—É—Å–∫–æ–≤'] > 0].sort_values('% –ø—Ä–æ–ø—É—Å–∫–æ–≤', ascending=False)
    if not missing_df.empty:
        st.dataframe(missing_df)
    else:
        st.write("–ü—Ä–æ–ø—É—Å–∫–æ–≤ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ.")

    # --- 3. –î—É–±–ª–∏–∫–∞—Ç—ã ---
    st.subheader("3. –î—É–±–ª–∏–∫–∞—Ç—ã")
    full_dup = df_raw.duplicated().sum()
    id_year_dup = df_raw.duplicated(subset=['id', 'year']).sum()
    st.write(f"- **–ü–æ–ª–Ω—ã–µ –¥—É–±–ª–∏–∫–∞—Ç—ã —Å—Ç—Ä–æ–∫**: {full_dup}")
    st.write(f"- **–î—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –≤—É–∑—É + –≥–æ–¥** (`id` + `year`): {id_year_dup}")

    # --- 4. –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è ---
    st.subheader("4. –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è")
    issues = []
    if issues:
        for issue in issues:
            st.write(issue)
    else:
        st.write("‚úÖ –í—Å–µ —á–∏—Å–ª–æ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ –æ–∂–∏–¥–∞–µ–º—ã—Ö –¥–∏–∞–ø–∞–∑–æ–Ω–∞—Ö.")

    # --- 5. –ü–æ–ª–Ω–æ—Ç–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤—É–∑–∞–º ---
    st.subheader("5. –ü–æ–ª–Ω–æ—Ç–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤")
    years_per_univ = df_raw.groupby('name_short')['year'].nunique()
    full_period_count = (years_per_univ == 5).sum()
    total_univ = df_raw['name_short'].nunique()
    st.write(f"- –í—É–∑–æ–≤ —Å –¥–∞–Ω–Ω—ã–º–∏ –∑–∞ –≤—Å–µ 5 –ª–µ—Ç (2013‚Äì2017): **{full_period_count} –∏–∑ {total_univ}** ({full_period_count / total_univ * 100:.1f}%)")

    # --- 6. –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –ø–æ —Å—Ç–æ–ª–±—Ü–∞–º ---
    st.subheader("6. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –ø–æ —Å—Ç–æ–ª–±—Ü–∞–º")
    missing_pct_all = (df_raw.isna().mean() * 100).sort_values(ascending=False)
    fig_missing = px.bar(
        x=missing_pct_all.index,
        y=missing_pct_all.values,
        labels={'x': '–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å', 'y': '% –ø—Ä–æ–ø—É—Å–∫–æ–≤'},
        title='–ü—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–æ–ø—É—Å–∫–æ–≤ –ø–æ —Å—Ç–æ–ª–±—Ü–∞–º'
    )
    fig_missing.update_layout(xaxis_tickangle=-45)
    st.plotly_chart(fig_missing, use_container_width=True)

# === –ó–ê–î–ê–ß–ê 2: –ê–ù–ê–õ–ò–ó `e1` ===
elif task == "2. –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–∏—ë–º–∞ –∞–±–∏—Ç—É—Ä–∏–µ–Ω—Ç–æ–≤":
    st.title("üìä –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–∏—ë–º–∞ –∞–±–∏—Ç—É—Ä–∏–µ–Ω—Ç–æ–≤")
    st.markdown("–≠—Ç–æ—Ç –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å –æ—Ç—Ä–∞–∂–∞–µ—Ç **—Å—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª –ï–ì–≠ –ø–æ—Å—Ç—É–ø–∞—é—â–∏—Ö**, —Å —É—á—ë—Ç–æ–º —Ç–æ–≥–æ, —á—Ç–æ –ª—å–≥–æ—Ç–Ω–∏–∫–∏ (–ø–æ—Å—Ç—É–ø–∏–≤—à–∏–µ –±–µ–∑ —ç–∫–∑–∞–º–µ–Ω–æ–≤) —Å—á–∏—Ç–∞—é—Ç—Å—è –Ω–∞–±—Ä–∞–≤—à–∏–º–∏ **100 –±–∞–ª–ª–æ–≤**.")
    st.dataframe(filtered_df['e1'].describe().to_frame().rename(columns={'e1': metric_labels['e1']}))

    col1, col2 = st.columns(2)
    with col1:
        fig1 = px.box(filtered_df, y='e1', labels={'e1': metric_labels['e1']})
        st.plotly_chart(fig1, use_container_width=True)
    with col2:
        avg_fd = filtered_df.groupby('federal_district')['e1'].mean().reset_index()
        fig2 = px.bar(avg_fd, x='federal_district', y='e1', labels={'e1': metric_labels['e1'], 'federal_district': '–§–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –æ–∫—Ä—É–≥'})
        st.plotly_chart(fig2, use_container_width=True)

# === –ó–ê–î–ê–ß–ê 3: –ü–†–û–ì–ù–û–ó –ù–ê 2018 –ì–û–î ===
elif task == "3. –ü—Ä–æ–≥–Ω–æ–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–∏—ë–º–∞ –Ω–∞ 2018 –≥–æ–¥":
    st.title("üîÆ –ü—Ä–æ–≥–Ω–æ–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–∏—ë–º–∞ –∞–±–∏—Ç—É—Ä–∏–µ–Ω—Ç–æ–≤ –Ω–∞ 2018 –≥–æ–¥")
    univ = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –≤—É–∑", filtered_df['name_short'].unique())
    data = filtered_df[filtered_df['name_short'] == univ].sort_values('year')

    if len(data) < 2:
        st.warning("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö (–Ω—É–∂–Ω–æ ‚â•2 –≥–æ–¥–∞).")
    else:
        X = data[['year']].values
        y = data['e1'].values
        model = RandomForestRegressor(n_estimators=100, random_state=42)
        model.fit(X, y)
        pred = model.predict([[2018]])[0]
        st.metric("–ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ 2018 –≥.", f"{pred:.2f}")
        fig = px.line(data, x='year', y='e1', title=f"–î–∏–Ω–∞–º–∏–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–∏—ë–º–∞: {univ}", labels={'e1': metric_labels['e1'], 'year': '–ì–æ–¥'})
        fig.add_scatter(x=[2018], y=[pred], mode='markers+text', text=["–ü—Ä–æ–≥–Ω–æ–∑ 2018"], textposition="top center", marker=dict(color='red', size=10))
        st.plotly_chart(fig, use_container_width=True)

# === –ó–ê–î–ê–ß–ê 4: –§–ê–ö–¢–û–†–´ –í–õ–ò–Ø–ù–ò–Ø ===
elif task == "4. –§–∞–∫—Ç–æ—Ä—ã, –≤–ª–∏—è—é—â–∏–µ –Ω–∞ –±–∞–ª–ª—ã –∞–±–∏—Ç—É—Ä–µ–Ω—Ç–æ–≤":
    st.title("üîç –ö–∞–∫–∏–µ —Ñ–∞–∫—Ç–æ—Ä—ã –≤–ª–∏—è—é—Ç –Ω–∞ –±–∞–ª–ª—ã –∞–±–∏—Ç—É—Ä–µ–Ω—Ç–æ–≤?")
    features = ['e4', 'e5', 'e6', 'e8', 'phd_share', 'rnd', 'wos', 'scopus']
    df_corr = filtered_df[['e1'] + features].dropna()
    corr_columns = [metric_labels.get(col, col) for col in ['e1'] + features]
    df_corr_renamed = df_corr.copy()
    df_corr_renamed.columns = corr_columns
    corr_matrix = df_corr_renamed.corr()
    fig = px.imshow(corr_matrix, text_auto=".2f", aspect="auto", title="–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–∏—ë–º–∞ —Å –¥—Ä—É–≥–∏–º–∏ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è–º–∏", color_continuous_scale='Blues')
    fig.update_xaxes(side="top")
    fig.update_yaxes(autorange="reversed")
    st.plotly_chart(fig, use_container_width=True)

    X, y = df_corr[features], df_corr['e1']
    model = RandomForestRegressor(n_estimators=100, random_state=42)
    model.fit(X, y)
    importances = pd.Series(model.feature_importances_, index=features)
    importances.index = [metric_labels.get(col, col) for col in importances.index]
    importances = importances.sort_values(ascending=False)
    fig2 = px.bar(importances, title='–í–∞–∂–Ω–æ—Å—Ç—å —Ñ–∞–∫—Ç–æ—Ä–æ–≤ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–∏—ë–º–∞')
    st.plotly_chart(fig2, use_container_width=True)

# === –ó–ê–î–ê–ß–ê 5: –°–†–ê–í–ù–ï–ù–ò–ï –í–£–ó–û–í ===
elif task == "5. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—É–∑–æ–≤ –ø–æ –∫–ª—é—á–µ–≤—ã–º –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è–º":
    st.title("‚öñÔ∏è –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—É–∑–æ–≤")
    unis = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ –¥–æ 3 –≤—É–∑–æ–≤", filtered_df['name_short'].unique(), max_selections=3)
    if len(unis) >= 2:
        comp = filtered_df[filtered_df['name_short'].isin(unis) & (filtered_df['year'] == 2017)]
        if not comp.empty:
            comp.set_index('name_short', inplace=True)
            cols = ['e1', 'e6', 'e8', 'rnd', 'phd_share']
            comp = comp[cols]
            comp.rename(columns=metric_labels, inplace=True)
            st.dataframe(comp)
        else:
            st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∑–∞ 2017 –≥–æ–¥.")

# === –ó–ê–î–ê–ß–ê 6: –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –ê–ë–ò–¢–£–†–ò–ï–ù–¢–ê ===
elif task == "6. –ü–æ–¥–±–æ—Ä –≤—É–∑–∞ –ø–æ –≤–∞—à–∏–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º":
    st.title("üéì –ü–æ–¥–±–æ—Ä –≤—É–∑–∞ –ø–æ –≤–∞—à–∏–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º")
    st.markdown("""
    –í—ã–±–µ—Ä–∏—Ç–µ, –∫–∞–∫–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –¥–ª—è –≤–∞—Å –≤–∞–∂–Ω—ã –ø—Ä–∏ –≤—ã–±–æ—Ä–µ –≤—É–∑–∞.  
    –°–∏—Å—Ç–µ–º–∞ –æ—Ç—Ä–∞–Ω–∂–∏—Ä—É–µ—Ç –≤—É–∑—ã –∏ –ø–æ–∫–∞–∂–µ—Ç **—Ç–æ–ø-10 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π**.
    """)

    # –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏ –¥–ª—è –≤—ã–±–æ—Ä–∞
    criteria_options = {
        'e1': '–ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏—ë–º–∞ (–±–∞–ª–ª –ï–ì–≠ —Å –ª—å–≥–æ—Ç–Ω–∏–∫–∞–º–∏ = 100)',
        'e6': '–¢—Ä—É–¥–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –≤—ã–ø—É—Å–∫–Ω–∏–∫–æ–≤ (%)',
        'e8': '–ü–ü–° —Å —É—á—ë–Ω–æ–π —Å—Ç–µ–ø–µ–Ω—å—é –Ω–∞ 100 —Å—Ç—É–¥–µ–Ω—Ç–æ–≤',
        'rnd': '–û–±—â–∏–π –æ–±—ä—ë–º –ù–ò–û–ö–† (—Ç—ã—Å. —Ä—É–±.)',
        'phd_share': '–î–æ–ª—è –∞—Å–ø–∏—Ä–∞–Ω—Ç–æ–≤ (%)',
        'e5': '–ó–∞—Ä–ø–ª–∞—Ç–∞ –ü–ü–° –≤—ã—à–µ —Å—Ä–µ–¥–Ω–µ–π –ø–æ —Ä–µ–≥–∏–æ–Ω—É (%)'
    }

    # –í—ã–±–æ—Ä –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤
    selected_criteria = st.multiselect(
        "–í—ã–±–µ—Ä–∏—Ç–µ –≤–∞–∂–Ω—ã–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏ (–º–æ–∂–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ)",
        options=list(criteria_options.keys()),
        format_func=lambda x: criteria_options[x]
    )

    if not selected_criteria:
        st.info("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –∫—Ä–∏—Ç–µ—Ä–∏–π.")
    else:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –¥–∞–Ω–Ω—ã–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –≥–æ–¥ (2017)
        df_2017 = filtered_df[filtered_df['year'] == 2017].copy()

        if df_2017.empty:
            st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∑–∞ 2017 –≥–æ–¥ —Å —É—á—ë—Ç–æ–º —Ñ–∏–ª—å—Ç—Ä–æ–≤.")
        else:
            # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –≤—É–∑—ã —Å –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –ø–æ –≤—Å–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º
            df_valid = df_2017.dropna(subset=selected_criteria)

            if df_valid.empty:
                st.warning("–ù–µ—Ç –≤—É–∑–æ–≤ —Å –ø–æ–ª–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º.")
            else:
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–∞–∂–¥—ã–π –∫—Ä–∏—Ç–µ—Ä–∏–π (–ø—Ä–∏–≤–æ–¥–∏–º –∫ —à–∫–∞–ª–µ 0‚Äì1)
                for col in selected_criteria:
                    min_val = df_valid[col].min()
                    max_val = df_valid[col].max()
                    if max_val == min_val:
                        df_valid[f'{col}_norm'] = 1.0
                    else:
                        df_valid[f'{col}_norm'] = (df_valid[col] - min_val) / (max_val - min_val)

                # –°—á–∏—Ç–∞–µ–º –æ–±—â–∏–π –±–∞–ª–ª ‚Äî —Å—Ä–µ–¥–Ω–µ–µ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º
                norm_cols = [f'{col}_norm' for col in selected_criteria]
                df_valid['total_score'] = df_valid[norm_cols].mean(axis=1)

                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é
                df_top = df_valid.sort_values('total_score', ascending=False).head(10)

                # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                st.subheader("üèÜ –¢–æ–ø-10 —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã—Ö –≤—É–∑–æ–≤")
                result_df = df_top[['name_short'] + selected_criteria].copy()
                result_df.rename(columns={**metric_labels, 'name_short': '–í—É–∑'}, inplace=True)
                st.dataframe(result_df.reset_index(drop=True))

# === –ó–ê–î–ê–ß–ê 7: –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–Ø –í–£–ó–û–í ===
elif task == "7. –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –≤—É–∑–æ–≤":
    st.title("üß© –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –≤—É–∑–æ–≤ –ø–æ —Å—Ö–æ–∂–µ—Å—Ç–∏ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π")
    st.markdown("""
    –í—É–∑—ã –≥—Ä—É–ø–ø–∏—Ä—É—é—Ç—Å—è –Ω–∞ –∫–ª–∞—Å—Ç–µ—Ä—ã –ø–æ –∫–ª—é—á–µ–≤—ã–º –º–µ—Ç—Ä–∏–∫–∞–º:
    - –ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏—ë–º–∞ (`e1`)
    - –¢—Ä—É–¥–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (`e6`)
    - –ü–ü–° —Å —É—á—ë–Ω–æ–π —Å—Ç–µ–ø–µ–Ω—å—é (`e8`)
    - –û–±—ä—ë–º –ù–ò–û–ö–† (`rnd`)
    - –î–æ–ª—è –∞—Å–ø–∏—Ä–∞–Ω—Ç–æ–≤ (`phd_share`)

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–µ—Ç–æ–¥ **K-Means (5 –∫–ª–∞—Å—Ç–µ—Ä–æ–≤)** –Ω–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞ **2017 –≥–æ–¥**.
    """)

    # –ë–µ—Ä—ë–º –¥–∞–Ω–Ω—ã–µ –∑–∞ 2017 –≥–æ–¥
    df_2017 = filtered_df[filtered_df['year'] == 2017].copy()
    features = ['e1', 'e6', 'e8', 'rnd', 'phd_share']

    # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏
    df_clean = df_2017.dropna(subset=features)

    if df_clean.empty:
        st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∑–∞ 2017 –≥–æ–¥ —Å –ø–æ–ª–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –ø–æ –≤—Å–µ–º –º–µ—Ç—Ä–∏–∫–∞–º.")
    else:
        from sklearn.cluster import KMeans
        from sklearn.preprocessing import StandardScaler

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(df_clean[features])

        # –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è
        kmeans = KMeans(n_clusters=5, random_state=42)
        df_clean['cluster'] = kmeans.fit_predict(X_scaled)

        # –ü—Ä–æ—Ñ–∏–ª—å –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
        cluster_profile = df_clean.groupby('cluster')[features].mean()
        cluster_profile.index.name = '–ö–ª–∞—Å—Ç–µ—Ä'
        cluster_profile.rename(columns=metric_labels, inplace=True)

        st.subheader("üìä –ü—Ä–æ—Ñ–∏–ª—å –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (—Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è)")
        st.dataframe(cluster_profile)

        # –í—ã–±–æ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞
        selected_cluster = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –∫–ª–∞—Å—Ç–µ—Ä –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –≤—É–∑–æ–≤", sorted(df_clean['cluster'].unique()))

        # –í—É–∑—ã –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–º –∫–ª–∞—Å—Ç–µ—Ä–µ
        cluster_vuzes = df_clean[df_clean['cluster'] == selected_cluster][['name_short'] + features]
        cluster_vuzes.rename(columns={**metric_labels, 'name_short': '–í—É–∑'}, inplace=True)

        st.subheader(f"üéì –í—É–∑—ã –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ {selected_cluster}")
        st.dataframe(cluster_vuzes.reset_index(drop=True))

# === –ó–ê–î–ê–ß–ê 8: –ü–û–î–ë–û–† –í–£–ó–ê –ü–û –ë–ê–õ–õ–ê–ú –ï–ì–≠ ===
elif task == "8. –ü–æ–¥–±–æ—Ä –≤—É–∑–∞ –ø–æ –≤–∞—à–∏–º –±–∞–ª–ª–∞–º –ï–ì–≠":
    st.title("üéì –ü–æ–¥–±–æ—Ä –≤—É–∑–∞ –ø–æ –≤–∞—à–µ–º—É –±–∞–ª–ª—É –ï–ì–≠")
    st.markdown("""
    –í–≤–µ–¥–∏—Ç–µ **–≤–∞—à —Å—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª –ï–ì–≠**.  
    –°–∏—Å—Ç–µ–º–∞ –ø–æ–∫–∞–∂–µ—Ç **–≤—É–∑—ã, –≤ –∫–æ—Ç–æ—Ä—ã–µ –≤—ã –º–æ–∂–µ—Ç–µ –ø–æ—Å—Ç—É–ø–∏—Ç—å** –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö –∑–∞ 2017 –≥–æ–¥.
    """)

    # –í–≤–æ–¥ –±–∞–ª–ª–∞
    user_score = st.number_input(
        "–í–∞—à —Å—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª –ï–ì–≠ (–æ—Ç 0 –¥–æ 100)",
        min_value=0.0,
        max_value=100.0,
        value=70.0,
        step=0.5
    )

    if user_score < 0 or user_score > 100:
        st.warning("–°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª –ï–ì–≠ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ –æ—Ç 0 –¥–æ 100.")
    else:
        # –î–∞–Ω–Ω—ã–µ –∑–∞ 2017 –≥–æ–¥
        df_2017 = filtered_df[filtered_df['year'] == 2017].copy()

        # –í—É–∑—ã, –≥–¥–µ –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏—ë–º–∞ <= –≤–∞—à–µ–º—É –±–∞–ª–ª—É
        eligible = df_2017[df_2017['e1'] <= user_score].copy()
        eligible = eligible.sort_values('e1', ascending=False)

        if eligible.empty:
            st.warning("–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –ø–æ –≤–∞—à–µ–º—É –±–∞–ª–ª—É –Ω–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –≤—É–∑–æ–≤ —Å —É—á—ë—Ç–æ–º —Ñ–∏–ª—å—Ç—Ä–æ–≤.")
        else:
            st.subheader("üéØ –í—É–∑—ã, –≤ –∫–æ—Ç–æ—Ä—ã–µ –≤—ã –º–æ–∂–µ—Ç–µ –ø–æ—Å—Ç—É–ø–∏—Ç—å")
            result = eligible[['name_short', 'e1', 'e6', 'region_name']].copy()
            result.columns = ['–í—É–∑', '–ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏—ë–º–∞ (e1)', '–¢—Ä—É–¥–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (%)', '–†–µ–≥–∏–æ–Ω']
            st.dataframe(result.reset_index(drop=True))

            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ 2018
            st.subheader("üîÆ –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ 2018 –≥–æ–¥")
            st.write("–ù–µ–∫–æ—Ç–æ—Ä—ã–µ –≤—É–∑—ã –º–æ–≥—É—Ç —É–∂–µ—Å—Ç–æ—á–∏—Ç—å –∫–æ–Ω–∫—É—Ä—Å. –í–æ—Ç —Ç–µ, –≥–¥–µ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º—ã–π e1 –Ω–∞ 2018 –≥–æ–¥ –≤—Å—ë –µ—â—ë ‚â§ –≤–∞—à–µ–≥–æ –±–∞–ª–ª–∞:")

            # –°—Ç—Ä–æ–∏–º –ø—Ä–æ–≥–Ω–æ–∑ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≤—É–∑–∞
            eligible['e1_2018_pred'] = np.nan
            for idx, row in eligible.iterrows():
                univ_data = filtered_df[
                    (filtered_df['name_short'] == row['name_short']) &
                    (filtered_df['year'] <= 2017)
                ].sort_values('year')
                if len(univ_data) >= 2:
                    model = RandomForestRegressor(n_estimators=100, random_state=42)
                    model.fit(univ_data[['year']], univ_data['e1'])
                    pred_2018 = model.predict([[2018]])[0]
                    eligible.at[idx, 'e1_2018_pred'] = pred_2018

            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –ø—Ä–æ–≥–Ω–æ–∑—É
            safe_vuzes = eligible[eligible['e1_2018_pred'] <= user_score]
            if not safe_vuzes.empty:
                st.dataframe(safe_vuzes[['–í—É–∑', '–ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏—ë–º–∞ (e1)', 'e1_2018_pred', '–†–µ–≥–∏–æ–Ω']].rename(columns={
                    'e1_2018_pred': '–ü—Ä–æ–≥–Ω–æ–∑ e1 –Ω–∞ 2018'
                }).reset_index(drop=True))
            else:
                st.write("–ü–æ –ø—Ä–æ–≥–Ω–æ–∑—É –Ω–∞ 2018 –≥–æ–¥, –∫–æ–Ω–∫—É—Ä—Å –º–æ–∂–µ—Ç –≤—ã—Ä–∞—Å—Ç–∏ –≤—ã—à–µ –≤–∞—à–µ–≥–æ –±–∞–ª–ª–∞ –≤–æ –≤—Å–µ—Ö –≤—É–∑–∞—Ö.")
